# Moves Too Fast, Risk Systemic Blowback
- ğŸ“… æ¥æº: IEEE Spectrum AI
- ğŸ•’ å‘å¸ƒæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: 2025-08-01 00:00:03
- ğŸ”— [åŸæ–‡é“¾æ¥](https://spectrum.ieee.org/ai-systemic-blowback)

<img src="https://spectrum.ieee.org/media-library/medical-file-with-red-cross-is-pixelated-and-on-fire-against-a-blue-background.png?id=61330528&amp;width=1200&amp;height=800&amp;coordinates=0%2C180%2C0%2C180" /><br /><br /><p>One of the most sobering insights from Contributing Editor Robert N. Charetteâ€™s feature story in this issue is that the 20-year rollout of <a href="https://spectrum.ieee.org/electronic-health-records" target="_self">electronic health records (EHRs) in the United States</a> happened with an intentional disregard for interoperability. As a result, thousands of health care providers are â€œburdened with costly, poorly designed, and insecure EHR systems that have exacerbated clinician burnout, led to hundreds of millions of records lost in data breaches, and created new sources of medical errors,â€ Charette writes.</p><p>The U.S. government made this myopic decision in order to speed up EHR adoption, ignoring the longer-term costs. The operating mantra, says Charette, was that EHR systems â€œneeded to become operational before they could become interoperable.â€</p><p> You could call what happened next â€œunintended consequences,â€ but that would absolve decision-makers in government and industry for making choices they knew could compromise user experience, security, and patient outcomes. The results were entirely foreseeable. A more appropriate term might be â€œsystemic blowbackâ€â€”large-scale negative outcomes that result from decisions to accelerate the adoption of new technology without consideration for the broader potential impacts.</p><p> Once you see systemic blowback in one technological context, you start to see it in others. Case in point: the global deployment of artificial intelligence.</p><h2>AIâ€™s Impact on White-Collar Jobs</h2><p> In May, Dario Amodei, CEO of Anthropic, maker of Claude AI, <a href="https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic" rel="noopener noreferrer" target="_blank">told Axios that AI could wipe out half of all entry-level white-collar jobs</a>â€”and spike unemployment to 10 to 20 percent in the next one to five years. (U.S. unemployment was <a href="https://www.bls.gov/charts/employment-situation/civilian-unemployment-rate.htm" rel="noopener noreferrer" target="_blank">about 4 percent in June</a>.) â€œWe, as the producers of this technology, have a duty and an obligation to be honest about what is coming,â€ Amodei said. â€œI donâ€™t think this is on peopleâ€™s radar.â€</p><p> But Amodeiâ€™s acknowledgment of the potential harms of mass AI adoption comes off as just virtue signaling. Big AI, Amodei surmises, will continue to develop this technology so we can cure cancer, grow the economy 10 percent annually, and even balance the federal budget. And by the way, up to one in five people will soon be unemployed. That last partâ€”the harmâ€”is someone elseâ€™s problem to solve.</p><p>Computer programmers are feeling the harm right now. According to <em><em>The Washington Post</em></em>, <a href="https://www.washingtonpost.com/business/2025/03/14/programming-jobs-lost-artificial-intelligence/" rel="noopener noreferrer" target="_blank">more than a quarter of all coding jobs have vanished</a> in the last two years, with much of that loss attributable to AI usage. As <em><em>Spectrum</em></em> reported last month, <a href="https://spectrum.ieee.org/large-language-model-performance" target="_self">LLMs are improving at an exponential rate</a>, which doesnâ€™t augur well for the rest of the human workforce.</p><p class="pull-quote">â€œSystemic blowbackâ€â€”large-scale negative outcomes that result from decisions to accelerate the adoption of new technology without consideration for the broader potential impacts.</p><p><span>That includes people working in media. Ever since Google emerged as the home page of the Web in the early 2000s, media outlets operated under the assumption that Google would reliably crawl their sites and send audience their way.</span></p><p>Google blew up that deal when it introduced AI answers to its entire user base earlier this year. Since then, <em><em>Spectrum</em></em> has had about double the impressionsâ€”the times <em><em>Spectrum</em></em> content shows up on the search results page or, increasingly, in an AI answerâ€”and about 40 percent fewer click-throughs from people coming to our website to read the cited article. As Web traffic dies, so do the business models predicated on that traffic. Oh well, says Big AI, someone elseâ€™s problem.</p><p>But killing off the current information ecosystem means that AIs will increasingly ingest new content written by other AIs, because the humans who produced the content are gone or will be soon. Garbage in, garbage out. This time next year, donâ€™t be surprised when your shiny, new AI agent gives you a morning briefing thatâ€™s just off. Then Big AIâ€™s problem will be your problem. Sooner or later you too will feel the systemic blowback.</p>