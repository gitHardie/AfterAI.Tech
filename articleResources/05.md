# When Will AI Agents Be Ready for Autonomous Business Operations?
- ğŸ“… æ¥æº: IEEE Spectrum AI
- ğŸ•’ å‘å¸ƒæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: 2026-01-30 05:55:23
- ğŸ”— [åŸæ–‡é“¾æ¥](https://spectrum.ieee.org/ai-agent-benchmarks)

<img src="https://spectrum.ieee.org/media-library/illustration-of-punch-cards-with-some-shaped-like-chatbot-faces-on-a-wall-next-to-a-time-clock.jpg?id=63522131&amp;width=2000&amp;height=1500&amp;coordinates=0%2C0%2C0%2C0" /><br /><br /><p><a href="https://spectrum.ieee.org/tag/ai-agents" target="_self">AI agents</a> aboundâ€”and theyâ€™re increasingly gaining autonomy. From <a href="https://spectrum.ieee.org/ai-agents-computer-use" target="_self">navigating the web</a> to <a href="https://spectrum.ieee.org/evolutionary-ai-coding-agents" target="_self">recursively improving its own coding skills</a>, <a href="https://spectrum.ieee.org/tag/agentic-ai" target="_self">agentic AI</a> promises to <a href="https://spectrum.ieee.org/ai-agent-economy" target="_self">reorder the online economy</a> and redefine the <a href="https://spectrum.ieee.org/tag/internet" target="_self">internet</a>.</p><p>For enterprise environments, however, AI agents pose a huge risk. Shifting from augmentation to <a href="https://spectrum.ieee.org/tag/automation" target="_self">automation</a> can be a precarious move, especially when the entities involved will be given full rein to perform crucial actionsâ€”from fulfilling a simple financial transaction to coordinating complex <a href="https://spectrum.ieee.org/tag/supply-chain" target="_self">supply chains</a>.</p><p>To mitigate the risk, researchers at <a href="https://www.cmu.edu/" rel="noopener noreferrer" target="_blank">Carnegie Mellon University</a> and <a href="https://global.fujitsu/en-global" rel="noopener noreferrer" target="_blank">Fujitsu</a> developed three benchmarks that measure when <a href="https://spectrum.ieee.org/ai-agents-safety" target="_self">AI agents are safe</a> or effective enough to run business operations without human oversight. These benchmarks were presented at a <a href="https://sites.google.com/view/aaba4et" rel="noopener noreferrer" target="_blank">workshop</a> on 26 January as part of the 2026 <a href="https://aaai.org/conference/aaai/aaai-26/" rel="noopener noreferrer" target="_blank">AAAI Conference on Artificial Intelligence</a> held in Singapore.</p><h2>Safety first</h2><p>The first benchmark, called <a href="https://arxiv.org/abs/2505.19662v2" rel="noopener noreferrer" target="_blank">FieldWorkArena</a>, evaluates AI agents deployed in the field, particularly <a href="https://spectrum.ieee.org/tag/logistics" target="_self">logistics</a> and <a href="https://spectrum.ieee.org/tag/manufacturing" target="_self">manufacturing</a> environments like factories and warehouses. FieldWorkArena calculates the accuracy rate of agents tasked with detecting safety rule violations and deviations from work procedures, as well as generating incident reports. For instance, an AI agent that checks compliance with wearing personal protective equipment (PPE) in a high-risk zone will need to understand PPE standards, identify workers within the zone, analyze what theyâ€™re wearing and if it adheres to the standards, and report on the number of compliant personnel.</p><p>Instead of simulations, the benchmark employs real-world data sources, including work manuals, safety regulations, and images and videos captured on-site. <a href="https://www.st.keio.ac.jp/en/tprofile/ics/hideo.saito.html" rel="noopener noreferrer" target="_blank">Hideo Saito</a>, a professor at Japanâ€™s <a href="https://www.keio.ac.jp/en/" rel="noopener noreferrer" target="_blank">Keio University</a> who isnâ€™t involved with the research but is one of the workshopâ€™s organizers, emphasizes the importance of <a href="https://spectrum.ieee.org/tag/data-privacy" target="_self">data privacy</a> when collecting input datasets for agentic AI benchmarks, â€œespecially when you want to deploy such a dataset for commercial, nonacademic use.â€ Data for FieldWorkArena, for example, was obtained with the consent of those appearing in video footage, while faces and sensitive work areas were blurred to prevent identification.</p><p>The researchers assessed three multimodal <a href="https://spectrum.ieee.org/tag/large-language-models" target="_self">large language models</a> (<a href="https://spectrum.ieee.org/tag/llms" target="_self">LLMs</a>) capable of processing both image and text data: <a href="https://spectrum.ieee.org/tag/anthropic" target="_self">Anthropic</a>â€™s Claude Sonnet 3.7, <a href="https://spectrum.ieee.org/tag/google" target="_self">Google</a>â€™s Gemini 2.0 Flash, and <a href="https://spectrum.ieee.org/tag/openai" target="_self">OpenAI</a>â€™s GPT-4o. The results were bleak, with all three models obtaining low accuracy scores. Although they excelled in information extraction and <a href="https://spectrum.ieee.org/tag/image-recognition" target="_self">image recognition</a>, the LLMs sometimes <a href="https://spectrum.ieee.org/ai-hallucination" target="_self">hallucinated</a> and struggled with counting objects precisely and measuring specific distances.</p><p>These findings demonstrate the need for agentic AI benchmarks for businesses that are grounded by enterprise contexts and rooted in realistic tasks. Thatâ€™s why <a href="https://spectrum.ieee.org/tag/fujitsu" target="_self">Fujitsu</a> spearheaded FieldWorkArena, noticing a growing demand from its customers to gauge the efficiency of AI agents fine-tuned for field work, says <a href="https://www.linkedin.com/in/hiromichikobashi" rel="noopener noreferrer" target="_blank">Hiro Kobashi</a>, a senior project director of the <a href="https://global.fujitsu/en-us/local/technology/research/ai-labs" rel="noopener noreferrer" target="_blank">AI Lab</a> at <a href="https://global.fujitsu/en-global/technology/research" rel="noopener noreferrer" target="_blank">Fujitsu Research</a>. â€œCustomers are uncertain and concerned about LLMs, so we want to provide good, sufficient benchmarks for them,â€ he adds.</p><p class="shortcode-media shortcode-media-rebelmouse-image"> <img alt="Schematic explaining the flow of the fieldworkarena benchmark" class="rm-shortcode" id="40025" src="https://spectrum.ieee.org/media-library/schematic-explaining-the-flow-of-the-fieldworkarena-benchmark.jpg?id=63522144&amp;width=980" /> <small class="image-media media-caption">   Overall system configuration of FieldWorkArena.</small><small class="image-media media-photo-credit"><a href="https://arxiv.org/abs/2505.19662v2" target="_blank">Atsunori Moteki, Shoichi Masui et al.</a></small></p><h2>Data access without hallucination </h2><p>While FieldWorkArena can be accessed through its <a href="https://github.com/FujitsuResearch/FieldWorkArena/" rel="noopener noreferrer" target="_blank">GitHub repository</a>, Kobashi notes that the other two benchmarks presented at the workshop, ECHO (EvidenCe-prior Hallucination Observation) and an enterprise retrieval-augmented generation (RAG) benchmark, will be made available to the public within a month. ECHO evaluates the effectiveness of hallucination mitigation strategies for vision language models (VLMs), which are designed to answer questions about images or generate text from visual inputs. The results indicate that techniques such as cropping images so models focus their attention on relevant regions and applying <a href="https://spectrum.ieee.org/tag/reinforcement-learning" target="_self">reinforcement learning</a> for reasoning can minimize hallucinations in VLMs.</p><p>Meanwhile, the enterprise RAG benchmark appraises the ability of AI agents to retrieve data from an authoritative knowledge base and use that data to augment their generated responses. Metrics measured include retrieving the right areas related to a query and correctly reasoning from the retrieved information.</p><p>In the future, Kobashi and his team aim to expand the capabilities of the benchmarks theyâ€™ve created to accommodate other industries and use cases. â€œCustomer requests are so diverse. We canâ€™t cover all requests by utilizing one single benchmark, so we need to have many kinds of benchmarks,â€ he says.</p><p>Continuously updating benchmarks is another crucial next step the team plans to take. As AI agents evolve, their benchmark scores could also rise, reaching the point of minimal progress. This will then signal the need for newer, more comprehensive benchmarks that guide the development of better enterprise AI agents.</p>