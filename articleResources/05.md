# New AI Model Advances the â€œKissing Problemâ€ And More
- ğŸ“… æ¥æº: IEEE Spectrum AI
- ğŸ•’ å‘å¸ƒæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: 2025-05-15 05:33:07
- ğŸ”— [åŸæ–‡é“¾æ¥](https://spectrum.ieee.org/deepmind-alphaevolve)

<img src="https://spectrum.ieee.org/media-library/green-code-screen-on-top-of-green-pixilated-landscape-on-black-background.jpg?id=60214792&amp;width=1245&amp;height=700&amp;coordinates=0%2C115%2C0%2C115" /><br /><br /><p><span>Thereâ€™s a mathematical concept called the â€˜</span><a href="https://en.wikipedia.org/wiki/Kissing_number" target="_blank">kissing number</a><span>.â€™ Somewhat disappointingly, itâ€™s got nothing to do with actual kissing; It enumerates how many spheres can touch (or â€˜kissâ€™) a single sphere of equal size without crossing it. In one dimension, the kissing number is two. In two dimensions itâ€™s 6 (think the <em>New York Timesâ€™</em> <a href="https://www.nytimes.com/puzzles/spelling-bee" target="_blank">spelling bee puzzle</a> configuration). As the number of dimensions grows, the answer becomes less obvious: For most dimensionalities over 4, only upper and lower bounds on the kissing number are known. Now, an AI agent developed by Google DeepMind called AlphaEvolve has made its contribution to the problem, increasing the lower bound on the kissing number in 11 dimensions from 592 to 593.</span></p><p>This may seem like an incremental improvement on the problem, especially given that the upper bound on the kissing number in 11 dimensions is 868, so the unknown range is still quite large. But it represents a novel mathematical discovery by an AI agent, and challenges the idea that large language models are <a href="https://spectrum.ieee.org/ai-for-science-2" target="_self">not capable</a> of original scientific contributions. </p><p>And this is just one example of what AlphaEvolve has accomplished. â€œWe applied AlphaEvolve across a range of open problems in research mathematics, and we deliberately picked problems from different parts of math: analysis, combinatorics, geometry,â€ says <a href="https://www.linkedin.com/in/matejbalog/?originalSubdomain=uk" target="_blank">Matej Balog</a>, a research scientist at DeepMind that worked on the project. They found that for 75 percent of the problems, the AI model replicated the already known optimal solution. In 20 percent of cases, it found a new optimum that surpassed any known solution. â€œEvery single such case is a new discovery,â€ Balog says. (In the other 5 percent of cases, the AI converged on a solution that was worse than the known optimal one.)<strong></strong></p><p>The model also developed a new algorithm for matrix multiplicationâ€”the operation that underlies much of machine learning. A previous version of DeepMindâ€™s AI model, called AlphaTensor, had already <a href="https://spectrum.ieee.org/matrix-multiplication-deepmind" target="_self">beat</a> the previous best known algorithm, discovered in 1969, for multiplying 4 by 4 matrices. AlphaEvolve found a more general version of that improved algorithm.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Three blue diagram icons showing a data center, a chip, and multiple chips with arrows. " class="rm-shortcode" id="3d355" src="https://spectrum.ieee.org/media-library/three-blue-diagram-icons-showing-a-data-center-a-chip-and-multiple-chips-with-arrows.jpg?id=60214830&amp;width=980" />
<small class="image-media media-caption">DeepMindâ€™s AlphaEvolve made improvements to several practical problems at Google. </small><small class="image-media media-photo-credit">Google DeepMind</small></p><p>In addition to abstract math, the team also applied their model to practical problems Google as a company faces every day. The AI was also used to optimize data center orchestration to gain 1 percent improvement, to optimize the design of the next Google <a href="https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests" target="_blank">tensor processing unit</a>, and to discover an improvement to a kernel used in Gemini training leading to a 1 percent reduction in training time.</p><p>â€œItâ€™s very surprising that you can do so many different things with a single system,â€ says <a href="https://www.linkedin.com/in/alexander-novikov-b0a968a6/?originalSubdomain=uk" target="_blank">Alexander Novikov</a>, a senior research scientist at DeepMind who also worked on AlphaEvolve.</p><h2>How AlphaEvolve Works</h2><p>AlphaEvolve is able to be so general because it can be applied to almost any problem that can be expressed as code, and which can be checked by another piece of code. The user supplies an initial stab at the problemâ€”a program that solves the problem at hand, however suboptimallyâ€”and a verifier program that checks how well a piece of code meets the required criteria.</p><p>Then, a large language model, in this case Gemini, comes up with other candidate programs to solve the same problem, and each one is tested by the verifier. From there, AlphaEvolve uses a <a href="https://spectrum.ieee.org/fighting-buggy-code-with-genetic-algorithms" target="_self">genetic algorithm</a> such that the â€˜fittestâ€™ of the proposed solutions survive and evolve to the next generation. This process repeats until the solutions stop improving. </p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A chart with four components pointing to code" class="rm-shortcode" id="aadf6" src="https://spectrum.ieee.org/media-library/a-chart-with-four-components-pointing-to-code.jpg?id=60214833&amp;width=980" />
<small class="image-media media-caption">AlphaEvolve uses an ensemble of Gemini large language models (LLMs) in conjunction with an evaluation code, all orchestrated by a genetic algorithm to optimize a piece of code. </small><small class="image-media media-photo-credit">Google DeepMind</small></p><p>â€œLarge language models came around, and we started asking ourselves, is it the case that they are only going to add whatâ€™s in the training data, or can we actually use them to discover something completely new, new algorithms or new knowledge?â€ Balog says. This research, Balog claims, shows that â€œif you use the large language models in the right way, then you can, in a very precise sense, get something thatâ€™s provably new and provably correct in the form of an algorithm.â€</p><p>AlphaEvolve comes from a long lineage of DeepMindâ€™s models, going back to AlphaZero, which <a href="https://spectrum.ieee.org/can-machine-learning-teach-us-anything" target="_self">stunned the world</a> by learning to play chess, Go, and other games better than any human player without using any human knowledgeâ€”just by playing the game and using <a href="https://spectrum.ieee.org/tag/reinforcement-learning" target="_self">reinforcement learning</a> to master it. Another math-solving AI based on reinforcement learning, AlphaProof, <a href="https://spectrum.ieee.org/math-ai" target="_self">performed</a> at the silver-medalist level on the 2024 International Math Olympiad.</p><p>For AlphaEvolve, however, the team broke from the reinforcement learning tradition in favor of the genetic algorithm. â€œThe system is much simpler,â€ Balog says. â€œAnd that actually has consequences, that itâ€™s much easier to set up on a wide range of problems.â€</p><h2>The (Totally Not Scary) Future</h2><p>The team behind AlphaEvolve hopes to evolve their system in two ways.</p><p>First, they want to apply it to a broader range of problems, including those in the natural sciences. To pursue this goal, they are planning to open up an early access program for interested academics to use AlphaEvolve in their research. It may be harder to adapt the system to the natural sciences, as verification of proposed solutions may be less straightforward. But, Balog says, â€œwe know that in the natural sciences, there are plenty of simulators for different types of problems, and then those can be used within AlphaEvolve as well. And we are, in the future, very much interested in broadening the scope in this direction.â€</p><p>Second, they want to improve the system itself, perhaps by coupling it with another DeepMind project: the <a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/" rel="noopener noreferrer" target="_blank">AI co-scientist</a>. This AI also uses an LLM and a genetic algorithm, but it focuses on hypothesis generation in natural language. â€œThey develop these higher-level ideas and hypotheses,â€ Balog says. â€œIncorporating this component into AlphaEvolve-like systems, I believe, will allow us to go to higher levels of abstraction.â€</p><p>These prospects are exciting, but for some they may also sound menacingâ€”for example, AlphaEvolveâ€™s optimization of Gemini training may be seen as the beginning of recursively self-improving AI, which some <a href="https://medium.com/%40cognidownunder/the-unsettling-rise-of-self-improving-ai-agi-a-pandoras-box-of-potential-and-peril-4aaf5f720e2a" rel="noopener noreferrer" target="_blank">worry</a> would lead to a runaway intelligence explosion referred to as the <a href="https://spectrum.ieee.org/special-reports/singularity/" target="_self">singularity</a>. The DeepMind team maintains that that is not their goal, of course. â€œWe are excited to contribute to advancing AI that benefits humanity,â€ Novikov says.</p>