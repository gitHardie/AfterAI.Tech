# AI models can acquire backdoors from surprisingly few malicious documents
- ğŸ“… æ¥æº: Ars Technica AI
- ğŸ•’ å‘å¸ƒæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: 2025-10-10 06:03:21
- ğŸ”— [åŸæ–‡é“¾æ¥](https://arstechnica.com/ai/2025/10/ai-models-can-acquire-backdoors-from-surprisingly-few-malicious-documents/)

Anthropic study suggests "poison" training attacks don't scale with model size.