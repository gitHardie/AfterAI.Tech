# What to Look Out for When Acquiring AI Systems
- üìÖ Êù•Ê∫ê: IEEE Spectrum AI
- üïí ÂèëÂ∏ÉÊó∂Èó¥Ôºà‰∏úÂÖ´Âå∫Ôºâ: 2025-05-16 02:00:03
- üîó [ÂéüÊñáÈìæÊé•](https://spectrum.ieee.org/ieee-ai-3119-standards)

<img src="https://spectrum.ieee.org/media-library/conceptual-illustration-of-a-large-language-model.jpg?id=60221501&amp;width=1200&amp;height=800&amp;coordinates=203%2C0%2C204%2C0" /><br /><br /><p> For more than three years, an <a href="https://standards.ieee.org/" rel="noopener noreferrer" target="_blank">IEEE Standards Association</a> working group has been refining a draft standard for procuring artificial intelligence and automated decision systems, <a href="https://standards.ieee.org/ieee/3119/10729/" rel="noopener noreferrer" target="_blank">IEEE 3119-2025</a>. It is intended to help procurement teams identify and manage <a href="https://time.com/6303127/ai-future-danger-present-harms/" rel="noopener noreferrer" target="_blank">risks</a> in high-risk domains. Such systems are used by government entities involved in education, health, employment, and many other <a href="https://www.sciencedirect.com/science/article/pii/S0308596120300689?via%3Dihub" rel="noopener noreferrer" target="_blank">public sector</a> areas. Last year the working group partnered with a European Union agency to evaluate the draft standard‚Äôs components and to gather information about users‚Äô needs and their views on the standard‚Äôs value.</p><p>At the time, the <a href="https://spectrum.ieee.org/5-ways-strengthen-ai-acquisition" target="_blank">standard</a> included five<em> </em>processes to help users develop their solicitations and to identify, mitigate, and monitor harms commonly associated with <a href="https://ai-regulation.com/guidance-on-high-risk-ai-systems-under-eu-ai-act/" rel="noopener noreferrer" target="_blank">high-risk</a> AI systems.</p><p>Those processes were problem definition, vendor evaluation, solution evaluation, contract negotiation, and contract monitoring.</p><p>The EU agency‚Äôs feedback led the working group to reconsider the processes and the sequence of several activities. The final draft now includes an additional process: solicitation preparation, which comes right after the problem definition process. The working group believes the added process addresses the challenges organizations experience with preparing AI-specific solicitations, such as the need to add transparent and robust data requirements and to incorporate questions regarding the maturity of vendor AI governance.</p><p>The EU agency also emphasized that it‚Äôs essential to include solicitation preparation, which gives procurement teams additional opportunities to adapt their solicitations with technical requirements and questions regarding responsible AI system choices. Leaving space for adjustments is especially relevant when acquisitions of AI are occurring within <a href="https://opentools.ai/news/ai-regulation-in-2025-navigating-a-global-maze" rel="noopener noreferrer" target="_blank">emerging</a> and <a href="https://www.nature.com/articles/s41599-024-03560-x" rel="noopener noreferrer" target="_blank">changing regulatory environments</a>.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Flow chart of an AI procurement workflow, from pre-procurement, to proposal evaluation, contracting and post-procurement. Steps include problem definition, solicitation preparation, vendor evaluation, solution evaluation, contract negotiations and contract monitoring." class="rm-shortcode" id="bb181" src="https://spectrum.ieee.org/media-library/flow-chart-of-an-ai-procurement-workflow-from-pre-procurement-to-proposal-evaluation-contracting-and-post-procurement-steps.jpg?id=60221504&amp;width=980" />
<small class="image-media media-photo-credit">Gisele Waters</small></p><h2>IEEE 3119‚Äôs place in the standards ecosystem</h2><p>Currently there are several internationally accepted standards for <a href="https://www.iso.org/obp/ui/en/#iso:std:iso-iec:42001:ed-1:v1:en" rel="noopener noreferrer" target="_blank"><u>AI management</u></a>, <a href="https://ieeexplore.ieee.org/browse/standards/get-program/page/series?id=93" rel="noopener noreferrer" target="_blank"><u>AI ethics</u></a>, and general <a href="https://www.iso.org/obp/ui/en/#iso:std:iso-iec-ieee:41062:ed-2:v1:en" rel="noopener noreferrer" target="_blank"><u>software acquisition</u></a>. Those from the IEEE Standards Association and the <a href="https://www.iso.org/home.html" rel="noopener noreferrer" target="_blank"><u>International Organization for Standardization</u></a> target AI design, use, and life-cycle management.</p><p>Until now, there has been no internationally accepted, consensus-based standard that focuses on the procurement of AI tools and offers operational<strong> </strong>guidance for responsibly purchasing <a href="https://artificialintelligenceact.eu/article/6/" rel="noopener noreferrer" target="_blank"><u>high-risk AI systems</u></a> that serve the public interest.</p><p><span>The <a href="https://spectrum.ieee.org/guide-on-acquiring-ai-systems" target="_blank">IEEE 3119 standard</a> addresses that gap. Unlike the AI management standard ISO 42001 and other certifications related to generic AI oversight and risk governance, IEEE‚Äôs new standard offers a </span><a href="https://www.inq.law/post/the-risk-based-approach-to-ai-a-global-trend" target="_blank"><u>risk-based, operational</u><u><strong> </strong></u><u>approach</u></a><span> to help government agencies adapt </span><a href="https://www.governmentprocurement.com/news/the-seven-stages-of-government-procurement-what-they-are-and-what-they-mean" target="_blank"><u>traditional</u></a><span> procurement practices.</span></p><p>Governments have an important role to play in the responsible deployment of AI. However, market dynamics and unequal AI expertise between industry and government can be barriers that discourage success.</p><p>One of the standard‚Äôs core goals is to better inform procurement leaders about what they are buying before they make high-risk AI purchases. IEEE 3119 defines high-risk AI systems as those that make or are a substantial factor in making <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11189344/" target="_blank"><u>consequential decisions</u></a> that could have significant impacts<strong> </strong>on people, groups, or society. The definition is similar to the one used in Colorado‚Äôs 2034 <a href="https://www.skadden.com/insights/publications/2024/06/colorados-landmark-ai-act" target="_blank"><u>AI Act</u></a>, the first U.S. state-level law comprehensively addressing high-risk systems.</p><p>The standard‚Äôs processes, however, do complement ISO 42001 in many ways. The relationship between both is illustrated below.</p><h3>Relationship of processes in IEEE 3119 and ISO/IEC 42001:2023</h3><br /><table border="1" style="white-space: unset;" width="100%">
<tbody>
<tr>
<th>
<strong>IEEE 3119 clause</strong>
</th>
<th>
<strong>ISO/IEC 42001:2023 clause</strong>
</th>
</tr>
<tr>
<td>
		6 Problem definition
	</td>
<td>
		4.1 Understanding the organization and its context
		<br />
		4.2 Understanding the needs and expectations of interested parties
		<br />
		6.1.4 AI system impact assessment
		<br />
</td>
</tr>
<tr>
<td>
		7 Solicitation preparation process
	</td>
<td>
		4.3 Determining the scope of the AI management system
		<br />
		4.4 AI management system and its processes
		<br />
</td>
</tr>
<tr>
<td>
		8 Vendor evaluation process
	</td>
<td>
		5. Leadership (commitment, policies, roles, etc.)
		<br />
		6.1.2 AI risk assessment
		<br />
		7.1 Resources
		<br />
		7.2 Competence
		<br />
		7.3 Awareness
		<br />
</td>
</tr>
<tr>
<td>
		9 Solution evaluation process
	</td>
<td>
		4.3 Determining the scope of the AI management system
		<br />
		4.4 AI management system and its processes
		<br />
		6.1 Actions to address risks and opportunities
		<br />
		7.4 Communication
		<br />
		7.5 Documented information
		<br />
</td>
</tr>
<tr>
<td>
		10 Contract negotiation process
	</td>
<td>
		6.1.3 AI risk treatment
		<br />
		9.1 Monitoring, measurement, analysis, and evaluation
		<br />
		10.2 Nonconformity and corrective action
		<br />
</td>
</tr>
<tr>
<td>
		11 Contract monitoring process
	</td>
<td>
		4.4 AI management system
		<br />
		6.3 Planning of changes
		<br />
		7.1 Resources
		<br />
		7.2 Competence
		<br />
		7.5.2 Creating and updating documented information
		<br />
		7.5.3 Controlling documented information
		<br />
		8.1 Operational planning and control
		<br />
		8.2 AI risk assessment
		<br />
		8.3 AI risk treatment
		<br />
		8.4 AI system impact assessment
		<br />
		9.1 Monitoring, measurement, analysis, and evaluation
		<br />
		9.2 Internal audit<br />9.3 Management review
		<br />
		10.2 Nonconformity and corrective action
		<br />
</td>
</tr>
</tbody>
</table><p class="photo-credit">
	Source: IEEE 3119-2025 Working Group
</p><p>International standards, often characterized as <a href="https://www.brookings.edu/articles/soft-law-as-a-complement-to-ai-regulation/" target="_blank"><u>soft law</u></a>, are used to shape AI development and <a href="https://lsi.asulaw.org/softlaw/wp-content/uploads/sites/7/2023/12/Wallach-et-al_Soft-Law-Functions-in-the-International-Governance-of-AI.pdf" rel="noopener noreferrer" target="_blank"><u>encourage international cooperation</u></a> regarding its governance.</p><p>Hard laws for AI, or legally binding rules and obligations, are a work in progress around the world. In the United States, a <a href="https://iapp.org/media/pdf/resource_center/us_state_ai_governance_legislation_tracker.pdf" rel="noopener noreferrer" target="_blank"><u>patchwork</u></a> of state legislation governs different aspects of AI, and the approach to national AI regulation is <a href="https://www.govtech.com/artificial-intelligence/the-impacts-of-a-fragmented-ai-legislative-landscape" rel="noopener noreferrer" target="_blank"><u>fragmented</u></a>, with different federal agencies implementing their own guidelines.</p><p>Europe has led by passing the European Union‚Äôs <a href="https://artificialintelligenceact.eu/" rel="noopener noreferrer" target="_blank"><u>AI Act</u></a>, which began governing AI systems based on their risk levels when it went into effect last year.</p><p>But the world lacks <a href="https://www.nature.com/articles/s41599-024-03560-x" rel="noopener noreferrer" target="_blank"><u>regulatory hard laws</u></a> with an international scope.</p><p>The IEEE 3119-2025 standard does align with existing hard laws. Due to its focus on procurement, the standard supports the high-risk provisions outlined in the <a href="https://artificialintelligenceact.eu/chapter/3/" rel="noopener noreferrer" target="_blank"><u>EU AI Act‚Äôs Chapter III</u></a> and <a href="https://leg.colorado.gov/sites/default/files/images/fpf_legislation_policy_brief_the_colorado_ai_act_final.pdf" rel="noopener noreferrer" target="_blank"><u>Colorado‚Äôs AI Act</u></a>. The standard also conforms to the proposed <a href="https://legiscan.com/TX/bill/HB1709/2025" rel="noopener noreferrer" target="_blank"><u>Texas HB 1709</u></a> legislation, which would mandate reporting on the use of AI systems by certain business entities and state agencies.</p><p>Because <a href="https://public-buyers-community.ec.europa.eu/system/files/2023-05/Slides_Keegan_McBride_5XcbzBTbz0t605NhjuA2FmGE7Y_86850.pdf" rel="noopener noreferrer" target="_blank"><u>most AI systems used in the public sector</u></a> are procured rather than built in-house, IEEE 3119 applies to commercial AI products and services that don‚Äôt require <a href="https://www.aiact-info.eu/definitions/substantial-modification/" rel="noopener noreferrer" target="_blank"><u>substantial modifications</u></a> or customizations.</p><h2>The standard‚Äôs target audience</h2><p>The standard is intended for:</p><ul><li>Mid-level procurement professionals and interdisciplinary team members with a moderate level of AI governance and AI system knowledge.</li><li>Public- and private-sector procurement professionals who serve as coordinators or buyers, or have equivalent roles, within their entities.</li><li>Non-procurement managers and supervisors who are either responsible for procurement or oversee staff who provide procurement functions.</li><li>Professionals who are employed by governing entities involved with public education, utilities, transportation, and other publicly funded services that either work on or manage procurement and are interested in adapting purchasing processes for AI tools. </li><li>AI vendors seeking to understand new transparency and disclosure requirements for their high-risk commercial products and solutions. </li></ul><h2>Training program in the works </h2><p>The <a href="https://standards.ieee.org/" rel="noopener noreferrer" target="_blank"><u>IEEE Standards Association</u></a> has partnered with the <a href="https://www.aiprocurementlab.org/" rel="noopener noreferrer" target="_blank"><u>AI Procurement Lab</u></a> to offer the <a href="https://blp.ieee.org/responsible-procurement-of-ai/" rel="noopener noreferrer" target="_blank"><u>IEEE Responsible AI Procurement Training program</u></a>. The course covers how to apply the standard‚Äôs core processes and adapt current practices for the procurement of high-risk AI. </p><p>The standard includes over 26 tools and rubrics across the six processes, and the training program explains how to use many of these tools. For example, the training includes instructions on how to conduct a risk-appetite analysis, apply the vendor evaluation scoring guide to analyze <a href="https://firstanalytics.com/wp-content/uploads/Vetting-Vendor-AI-Claims.pdf" rel="noopener noreferrer" target="_blank"><u>AI vendor claims</u></a>, and create an AI procurement ‚Äúrisk register‚Äù tied to identified use-case risks and their potential mitigations. The training session is now available for purchase.</p><p>It‚Äôs still early days for AI integration. Decision makers don‚Äôt yet have much experience in purchasing AI for high-risk domains and in mitigating those risks. The IEEE 3119-2025 standard aims to support agencies build and strengthen their AI risk mitigation muscles. </p>