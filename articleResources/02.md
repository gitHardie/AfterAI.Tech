# So-called reasoning models are more efficient but not more capable than regular LLMs, study finds
- ğŸ“… æ¥æº: The Decoder
- ğŸ•’ å‘å¸ƒæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: 2025-11-12 03:49:48
- ğŸ”— [åŸæ–‡é“¾æ¥](https://the-decoder.com/so-called-reasoning-models-are-more-efficient-but-not-more-capable-than-regular-llms-study-finds/)

<p><img alt="A new study questions whether reinforcement learning with verifiable rewards (RLVR) actually improves the reasoning abilities of large language models - or merely helps to reproduce known solution paths more efficiently." class="attachment-full size-full wp-post-image" height="1024" src="https://the-decoder.com/wp-content/uploads/2025/04/rlvf_illustration_reinforcment_learning_tree.png" style="height: auto; margin-bottom: 10px;" width="1536" /></p>
<p>        A new study from Tsinghua University and Shanghai Jiao Tong University examines whether reinforcement learning with verifiable rewards (RLVR) helps large language models reason betterâ€”or simply makes them more efficient at repeating known solutions.</p>
<p>The article <a href="https://the-decoder.com/so-called-reasoning-models-are-more-efficient-but-not-more-capable-than-regular-llms-study-finds/">So-called reasoning models are more efficient but not more capable than regular LLMs, study finds</a> appeared first on <a href="https://the-decoder.com">THE DECODER</a>.</p>